import streamlit as st
from streamlit_chat import message
import sys
from pathlib import Path
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.rag_chain import RAGChain
from config.settings import DOCUMENTS_DIR

# OpenAI API ì„¤ì •
# OPENAI_API_KEY=your-api-key-here  # âŒ Python ì½”ë“œì—ì„œ ì´ë ‡ê²Œ ì“°ë©´ ì•ˆ ë©ë‹ˆë‹¤!

# ê¸°íƒ€ ì„¤ì •
# MODEL_NAME=gpt-3.5-turbo
# EMBEDDING_MODEL=text-embedding-3-small
# TEMPERATURE=0.7
# MAX_TOKENS=2000

# ê¸°ì¡´
LOCAL_LLM_API_BASE = "http://localhost:1234/v1"

# ë³€ê²½
LOCAL_LLM_API_BASE = "http://10.129.45.22:1234/v1"

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "rag_chain" not in st.session_state:
        st.session_state.rag_chain = RAGChain()
    if "processed_files" not in st.session_state:
        st.session_state.processed_files = set()

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.set_page_config(
        page_title="RAG ì±—ë´‡",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    st.title("ğŸ¤– RAG ì±—ë´‡")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“„ ë¬¸ì„œ ê´€ë¦¬")
        if st.button("ğŸ“‚ ë¬¸ì„œ ìë™ ì²˜ë¦¬ (documents í´ë”)"):
            with st.spinner("documents í´ë”ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                files = [f for f in os.listdir(DOCUMENTS_DIR) if (DOCUMENTS_DIR / f).is_file()]
                for file in files:
                    file_path = DOCUMENTS_DIR / file
                    # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
                    if str(file_path) not in st.session_state.processed_files:
                        try:
                            st.session_state.rag_chain.process_and_store_document(str(file_path))
                            st.session_state.processed_files.add(str(file_path))
                            st.success(f"{file} ì²˜ë¦¬ ì™„ë£Œ!")
                        except Exception as e:
                            st.error(f"{file} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    else:
                        st.info(f"{file} ì´ë¯¸ ì²˜ë¦¬ë¨")
            st.success("ëª¨ë“  ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!")
        st.divider()
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.session_state.processed_files.clear()
            st.session_state.rag_chain.reset_vector_store()
            st.success("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    chat_container = st.container()
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # ì±—ë´‡ ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            response = st.session_state.rag_chain.query(
                query=user_input,
                chat_history=st.session_state.messages[:-1]  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
            )
        
        # ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": response})
    
    # ë©”ì‹œì§€ í‘œì‹œ
    with chat_container:
        for i, msg in enumerate(st.session_state.messages):
            if msg["role"] == "user":
                message(msg["content"], is_user=True, key=f"user_{i}")
            else:
                message(msg["content"], is_user=False, key=f"assistant_{i}")

if __name__ == "__main__":
    main() 